# AdvancedIntentDetector — документация

## Назначение

**AdvancedIntentDetector** — детерминированный классификатор интентов (Intent) для think-пайплайна. Его задача — по входному `userText` определить, к какому типу относится сообщение пользователя (например: `GREETING`, `QUESTION`, `REQUEST`, …), и вернуть:

- конкретный `Intent` при достаточной уверенности,
- либо `Intent.UNKNOWN`, если уверенности недостаточно.

Ключевые цели реализации:

- **стабильность и воспроизводимость** (без случайности),
- **наблюдаемость** (debug-лог с объяснением),
- **устойчивость к шуму** (Unicode нормализация, RU/EN),
- готовность к **адаптации** через `NeuronGraph` (опционально),
- enterprise-режим: **конфигурирование весов**, приоритетов и порогов.


---

## Основные возможности

### 1) Фичи: токены, биграммы, сигналы формы
Детектор превращает текст в набор признаков (features):

- `tok:<word>` — токены (слова/цифры/`_`), Unicode-aware
- `bg:<w1>_<w2>` — биграммы соседних токенов (если `useBigrams=true`)
- сигналы (shape / punctuation):
    - `sig:qm` — если есть `?`
    - `sig:ex` — если есть `!`
    - `sig:whyshape` — если первый токен похож на вопросительную форму (RU/EN)
    - `sig:code` — если текст “выглядит как код”
    - `sig:len_short` / `sig:len_long` — короткие/длинные сообщения

Все признаки — **строковые ключи**, которые ищутся в таблице весов.

### 2) Взвешенное суммирование (linear scorer)
Для каждого `Intent` считается сумма: score(intent) = prior(intent) + Σ weight(intent, feature_i) * multiplier_i
- `prior` — опциональный bias (например, чуть чаще считать “вопросом”)
- `multiplier` = 1, либо (в режиме `uniqueTokens=false`) может масштабироваться по числу повторов токена

### 3) Нормализация по длине
Если `lengthNormPow > 0`, итоговый score делится на: score /= tokenCount ^ lengthNormPow


Это снижает преимущество длинных сообщений.

### 4) Confidence + margin gate
Детектор не просто берёт `argmax(score)`, а применяет контроль качества:

- `conf = softmax(best)` — доля best-intent в softmax по всем интентам
- `margin = bestScore - secondBestScore`

Возвращается best intent **только если**:

- `conf >= minConfidence`
- `margin >= minMargin`

Иначе — `UNKNOWN`.

### 5) Debug-объяснимость (TopHits)
Если `debugLog=true` и включён DEBUG уровень логов:

- печатается summary:
    - исходный и нормализованный текст
    - число токенов и признаков
    - лучший интент
    - confidence, margin
    - ok / not ok
- дополнительно выводятся **TopHits**: признаки, давшие вклад в победивший интент (топ-10 по `add`).

Это ускоряет настройку весов и поиск ошибок.

### 6) Авто-bootstrap (работает из коробки)
Если `autoBootstrap=true` и веса вообще не заданы (`isAllWeightsEmpty()`), детектор ставит небольшой RU/EN bootstrap:

- приветствия (`привет`, `hello`, `добрый день`, …)
- запросы (`сделай`, `обнови`, `пришли`, …)
- вопросы (`sig:qm`, `sig:whyshape`)

В прод-режиме “no hardcode” рекомендуется:

- `autoBootstrap=false`
- веса инжектить из corpora/LTM/config


---

## Принцип работы (pipeline)

### Вход
`detect(String userText)`

### Шаги

1) **Trim + пустой текст → UNKNOWN**

2) **Normalize (Unicode NFKC)**
- приводит текст к канонической форме
- заменяет длинные тире на `-`
- заменяет NBSP на пробел

3) **Tokenize**
- Regex: `[\\p{L}\\p{Nd}_]{2,}`
- максимум токенов: `MAX_TOKENS = 160`
- `uniqueTokens=true`: токены превращаются в `LinkedHashSet` (уникальные)
- `uniqueTokens=false`: сохраняются повторы + считается `counts`

4) **Build features**
- `tok:*` для каждого токена
- `bg:*` для соседних токенов (если включено)
- `sig:*` на основе формы текста

5) **Score**
- по каждому интенту суммируются веса по совпавшим feature’ам
- добавляется delta от `NeuronGraph` (если подключён)
- применяется length normalization (если включена)

6) **Rank**
- выбирается best и second best по score

7) **Confidence**
- считается softmax(best) по интентам
- проверяются пороги `minConfidence` + `minMargin`

8) **Return**
- best intent, если ok
- иначе UNKNOWN


---

## Конфигурация (Config)

Создаётся через `AdvancedIntentDetector.Config.builder()`.

### Основные поля
- `weights: Map<Intent, Map<String, Double>>`  
  Ключи вида `tok:*`, `bg:*`, `sig:*`.

- `priors: Map<Intent, Double>`  
  Сдвиг вероятности интента.

- `minConfidence` (по умолчанию `0.62`)  
  Минимальная softmax-уверенность.

- `minMargin` (по умолчанию `0.10`)  
  Минимальный разрыв между 1 и 2 местом.

- `lengthNormPow` (по умолчанию `0.35`)  
  Нормализация длины: `0..1`. `0` отключает.

- `useBigrams` (по умолчанию `true`)  
  Включить признаки биграмм.

- `uniqueTokens` (по умолчанию `true`)  
  Токены уникализируются (меньше шума, быстрее).

- `debugLog` (по умолчанию `false`)  
  Вывод объяснений.

- `autoBootstrap` (по умолчанию `true`)  
  Включить минимальный bootstrap, если веса пусты.

### Рекомендованные профили
**1) Prod “no hardcode”**
- `autoBootstrap=false`
- веса загружать из corpora/config
- `debugLog=false` (или sampling)

**2) Dev / tuning**
- `debugLog=true`
- `autoBootstrap=true` (пока нет весов)
- постепенно заменять bootstrap реальными весами


---

## Ограничения

### 1) Линейная модель признаков
Это “взвешенная сумма по фичам”. Плюсы: детерминизм и объяснимость. Минусы:

- хуже нейросетевых intent-классификаторов на сложных фразах,
- требует обновления весов при смене домена.

### 2) Слабая морфология RU/EN
Токены берутся как есть. Без лемматизации/стемминга:
- “сделай” и “сделаете” — разные токены
- “привет” и “приветик” — разные токены

### 3) `uniqueTokens=true` обнуляет “частотность”
Это ускоряет и снижает шум, но частота слов не усиливает сигнал. Для некоторых кейсов полезен `uniqueTokens=false`.

### 4) Биграммы чувствительны к порядку
Биграммы зависят от последовательности токенов и могут терять устойчивость к перестановкам.

### 5) Softmax по “сырым score”
Softmax считается по линейным score. При сильно разном масштабе весов возможна некорректная калибровка `conf`.


---

## Типовые проблемы и диагностика

### 1) “Всегда UNKNOWN”
**Причина:**
- веса пустые
- autoBootstrap выключен

**Решение:**
- включить `autoBootstrap=true` временно
- или инжектить веса из corpora/config

### 2) Перекосы из-за `sig:*`
Если вес `sig:qm` слишком большой — всё с `?` превращается в QUESTION.

**Решение:**
- снижать веса `sig:*`
- повышать `minMargin` (например 0.15..0.25)

### 3) Ложный `sig:code`
Эвристика “похоже на код” может срабатывать на техтексте с ключевыми словами.

**Решение:**
- уменьшить влияние `sig:code` (если где-то добавлен вес)
- либо выделить отдельный `Intent.CODE` (если в проекте он есть)

### 4) Слишком строгие пороги → много UNKNOWN
**Решение:**
- снизить `minConfidence` (например 0.55)
- снизить `minMargin` (например 0.06)
- включить `debugLog=true` и смотреть реальные `conf/margin`


---

## Точки роста

### 1) Веса из corpora + обучение (без магии)
Сильный enterprise-подход:
- хранить веса в `intent_weights.jsonl`
- позволить `AdvancedLearner` обновлять веса (дельты)
- логировать апдейты (какие фичи изменились)

### 2) Морфология RU без тяжёлых зависимостей
Минимально:
- `ё → е`
- обработка дефисов (“сделай-ка”)
- простой стемминг/правила для частых форм

### 3) Temperature для softmax
Добавить параметр `temperature`: softmax(exp((score-max)/T))
чтобы калибровать уверенность при разных шкалах весов.

### 4) Ускорение хранения/lookup фич
Если фичей станет много:
- feature hashing
- более компактные структуры для весов и counts

### 5) Explainability для NeuronGraph
Сейчас граф добавляет дельту “вслепую”. Можно:
- ограничить вклад (clip),
- выводить top-contributions от графа в debug.

### 6) Метрики и наблюдаемость в проде
- частота UNKNOWN
- распределения conf/margin
- топ-индикаторы по интентам
- алерты на регрессии (“UNKNOWN вырос на 30%”)


---

## Идеи улучшений (список)

### Высокий приоритет
1. Внешняя конфигурация весов (corpora/config), `autoBootstrap=false` в проде.
2. Калибровка порогов `minConfidence/minMargin` на реальном датасете.
3. Улучшение токенизации RU (ё/дефисы/формы).

### Средний приоритет
4. Temperature softmax.
5. Семантические признаки (классы слов: просьба/вопрос/приветствие).
6. Отдельный интент `CODE` (если требуется).

### Низкий приоритет
7. Feature hashing.
8. Explainability для NeuronGraph.
9. Dev A/B тестирование порогов и весов.


---

## Практические советы

- Если в логах часто `intent=UNKNOWN` на простых фразах:
    - включите `autoBootstrap=true` временно,
    - включите `debugLog=true`,
    - перенесите bootstrap-слова в corpora-веса и отключите bootstrap.

- Для enterprise режима:
    - bootstrap выключен,
    - веса версионируются как данные (корпуса) + CI тесты на регрессию интентов.


---

## Ключевые места кода

- `detect()` — основной pipeline детекции
- `tokenize()` — токены и counts
- `buildFeatures()` — tok/bg/sig признаки
- `rank()` + `softmaxConfidence()` — выбор best + confidence/margin gate
- `dumpTopHits()` — объяснимость
- `installMinimalBootstrap()` — out-of-box bootstrap (опционально)

